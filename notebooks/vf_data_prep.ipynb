{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: (5222904, 22)\n",
      "\n",
      "Preparing training data...\n",
      "Cleaning dataset...\n",
      "Creating advanced features...\n",
      "Creating text features...\n",
      "Combining features...\n",
      "Feature matrix shape: (5222904, 111)\n",
      "Target vector shape: (5222904,)\n",
      "\n",
      "Training data saved to: /Users/benben/workspace/NUS_Projects/food-recommender/data/training_data.pkl\n",
      "TF-IDF vectorizer saved to: /Users/benben/workspace/NUS_Projects/food-recommender/data/tfidf_vectorizer.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ast\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# --- 1. Data Cleaning & Feature Engineering Functions ---\n",
    "\n",
    "def clean_dataset(df):\n",
    "    cleaned_df = df.copy()\n",
    "    numeric_columns = {\n",
    "        'stars_review': float,\n",
    "        'useful': int,\n",
    "        'funny': int,\n",
    "        'cool': int,\n",
    "        'latitude': float,\n",
    "        'longitude': float,\n",
    "        'stars_business': float,\n",
    "        'review_count': int,\n",
    "        'is_open': int\n",
    "    }\n",
    "    for col, dtype in numeric_columns.items():\n",
    "        cleaned_df[col] = pd.to_numeric(cleaned_df[col], errors='coerce')\n",
    "\n",
    "    cleaned_df['date'] = pd.to_datetime(cleaned_df['date'], errors='coerce')\n",
    "\n",
    "    def parse_attributes(attr_str):\n",
    "        if pd.isna(attr_str):\n",
    "            return {}\n",
    "        try:\n",
    "            return ast.literal_eval(str(attr_str))\n",
    "        except:\n",
    "            try:\n",
    "                return json.loads(str(attr_str).replace(\"'\", '\"'))\n",
    "            except:\n",
    "                return {}\n",
    "    cleaned_df['attributes'] = cleaned_df['attributes'].apply(parse_attributes)\n",
    "\n",
    "    cleaned_df['price_range'] = cleaned_df['attributes'].apply(\n",
    "        lambda x: x.get('RestaurantsPriceRange2') if isinstance(x, dict) else None\n",
    "    )\n",
    "    cleaned_df['price_range'] = pd.to_numeric(cleaned_df['price_range'], errors='coerce').fillna(0)\n",
    "\n",
    "    cleaned_df['categories'] = cleaned_df['categories'].fillna('')\n",
    "    cleaned_df['category_list'] = cleaned_df['categories'].str.split(', ')\n",
    "\n",
    "    return cleaned_df\n",
    "\n",
    "def create_advanced_features(df):\n",
    "    features = pd.DataFrame()\n",
    "    features['business_rating'] = df['stars_business']  # (will be dropped later for training)\n",
    "    features['review_count'] = df['review_count']\n",
    "    features['price_range'] = df['price_range']\n",
    "    features['is_open'] = df['is_open']\n",
    "\n",
    "    features['review_rating'] = df['stars_review']  # (will be dropped later)\n",
    "    features['review_useful'] = df['useful']\n",
    "    features['review_funny'] = df['funny']\n",
    "    features['review_cool'] = df['cool']\n",
    "\n",
    "    features['review_engagement'] = (features['review_useful'] +\n",
    "                                     features['review_funny'] +\n",
    "                                     features['review_cool'])\n",
    "\n",
    "    features['value_score'] = np.where(\n",
    "        features['price_range'] > 0,\n",
    "        features['business_rating'] / features['price_range'],\n",
    "        features['business_rating']\n",
    "    )\n",
    "\n",
    "    features['popularity_score'] = np.log1p(features['review_count'])\n",
    "\n",
    "    features['rating_deviation'] = abs(features['review_rating'] - features['business_rating'])\n",
    "\n",
    "    features['latitude'] = df['latitude']\n",
    "    features['longitude'] = df['longitude']\n",
    "\n",
    "    coords = df[['latitude', 'longitude']].values\n",
    "    kmeans = KMeans(n_clusters=min(50, len(df)), random_state=42)\n",
    "    features['location_cluster'] = kmeans.fit_predict(coords)\n",
    "\n",
    "    return features\n",
    "\n",
    "def create_text_features(df, max_features=100):\n",
    "    tfidf = TfidfVectorizer(\n",
    "        max_features=max_features,\n",
    "        stop_words='english',\n",
    "        ngram_range=(1, 2)\n",
    "    )\n",
    "    text_data = df['text'].fillna('') + ' ' + df['categories'].fillna('')\n",
    "    text_features = tfidf.fit_transform(text_data)\n",
    "    text_features_df = pd.DataFrame(\n",
    "        text_features.toarray(),\n",
    "        columns=[f'text_feature_{i}' for i in range(max_features)]\n",
    "    )\n",
    "    return text_features_df, tfidf\n",
    "\n",
    "def prepare_final_dataset(merged_df):\n",
    "    print(\"Cleaning dataset...\")\n",
    "    cleaned_df = clean_dataset(merged_df)\n",
    "\n",
    "    print(\"Creating advanced features...\")\n",
    "    features_df = create_advanced_features(cleaned_df)\n",
    "\n",
    "    print(\"Creating text features...\")\n",
    "    # Unpack the tuple: use only the text features DataFrame\n",
    "    text_features_df, _ = create_text_features(cleaned_df)\n",
    "\n",
    "    print(\"Combining features...\")\n",
    "    final_features = pd.concat([features_df, text_features_df], axis=1)\n",
    "\n",
    "    return final_features, cleaned_df\n",
    "\n",
    "def prepare_training_data(merged_df):\n",
    "    final_features, cleaned_df = prepare_final_dataset(merged_df)\n",
    "    cleaned_df['ranking_score'] = cleaned_df['stars_business'] * np.log1p(cleaned_df['review_count'])\n",
    "    features_to_drop = ['business_rating', 'review_rating', 'value_score', 'rating_deviation']\n",
    "    X = final_features.drop(columns=[col for col in features_to_drop if col in final_features.columns], errors='ignore')\n",
    "    y = cleaned_df['ranking_score']\n",
    "    return X, y\n",
    "\n",
    "# --- 2. Create and Save the Training Dataset and TF-IDF Vectorizer ---\n",
    "\n",
    "# Set your data folder path (make sure this folder exists)\n",
    "data_folder = \"/Users/benben/workspace/NUS_Projects/food-recommender/data\"\n",
    "if not os.path.exists(data_folder):\n",
    "    os.makedirs(data_folder)\n",
    "\n",
    "# Read the merged CSV file\n",
    "merged_file = \"/Users/benben/workspace/NUS_Projects/food-recommender/data/merged_food_reviews.csv\"\n",
    "merged_file_df = pd.read_csv(merged_file)\n",
    "print(\"Original dataset shape:\", merged_file_df.shape)\n",
    "\n",
    "print(\"\\nPreparing training data...\")\n",
    "X, y = prepare_training_data(merged_file_df)\n",
    "print(\"Feature matrix shape:\", X.shape)\n",
    "print(\"Target vector shape:\", y.shape)\n",
    "\n",
    "# Save the training data to the data folder\n",
    "data_filename = os.path.join(data_folder, \"training_data.pkl\")\n",
    "with open(data_filename, 'wb') as f:\n",
    "    pickle.dump((X, y), f)\n",
    "print(f\"\\nTraining data saved to: {data_filename}\")\n",
    "\n",
    "# Re-create cleaned_df from merged_file_df for saving the TF-IDF vectorizer\n",
    "cleaned_df = clean_dataset(merged_file_df)\n",
    "_, fitted_tfidf = create_text_features(cleaned_df)\n",
    "tfidf_filename = os.path.join(data_folder, \"tfidf_vectorizer.pkl\")\n",
    "with open(tfidf_filename, \"wb\") as f:\n",
    "    pickle.dump(fitted_tfidf, f)\n",
    "print(f\"TF-IDF vectorizer saved to: {tfidf_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "file_path = \"../data/training_data.pkl\"\n",
    "\n",
    "with open(file_path, \"rb\") as f:\n",
    "    data = pickle.load(f)  # Load the entire object\n",
    "\n",
    "print(type(data))  # Check the type of the data\n",
    "print(len(data) if hasattr(data, '__len__') else \"No length attribute\")  # If it's a list or dict, print length\n",
    "\n",
    "# If it's a dictionary, preview some keys\n",
    "if isinstance(data, dict):\n",
    "    print(list(data.keys())[:10])  # Print first 10 keys\n",
    "\n",
    "# If it's a list, preview first few elements\n",
    "elif isinstance(data, list):\n",
    "    print(data[:5])  # Print first 5 elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(type(data[0]))  # Type of first element\n",
    "print(type(data[1]))  # Type of second element\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5222904 entries, 0 to 5222903\n",
      "Columns: 111 entries, review_count to text_feature_99\n",
      "dtypes: float64(104), int32(1), int64(6)\n",
      "memory usage: 4.3 GB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_count</th>\n",
       "      <th>price_range</th>\n",
       "      <th>is_open</th>\n",
       "      <th>review_useful</th>\n",
       "      <th>review_funny</th>\n",
       "      <th>review_cool</th>\n",
       "      <th>review_engagement</th>\n",
       "      <th>popularity_score</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>...</th>\n",
       "      <th>text_feature_90</th>\n",
       "      <th>text_feature_91</th>\n",
       "      <th>text_feature_92</th>\n",
       "      <th>text_feature_93</th>\n",
       "      <th>text_feature_94</th>\n",
       "      <th>text_feature_95</th>\n",
       "      <th>text_feature_96</th>\n",
       "      <th>text_feature_97</th>\n",
       "      <th>text_feature_98</th>\n",
       "      <th>text_feature_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>169</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.135798</td>\n",
       "      <td>40.210196</td>\n",
       "      <td>-75.223639</td>\n",
       "      <td>...</td>\n",
       "      <td>0.163739</td>\n",
       "      <td>0.23642</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.233233</td>\n",
       "      <td>0.225804</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.871201</td>\n",
       "      <td>32.207233</td>\n",
       "      <td>-110.980864</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>181</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5.204007</td>\n",
       "      <td>40.079848</td>\n",
       "      <td>-75.025080</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.398945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.496508</td>\n",
       "      <td>29.962102</td>\n",
       "      <td>-90.087958</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136585</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.141275</td>\n",
       "      <td>0.163491</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.358466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>273</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5.613128</td>\n",
       "      <td>39.938013</td>\n",
       "      <td>-75.148131</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.338898</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 111 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_count  price_range  is_open  review_useful  review_funny  \\\n",
       "0           169          2.0        1              0             0   \n",
       "1            47          1.0        1              0             0   \n",
       "2           181          2.0        1              1             0   \n",
       "3            32          2.0        0              1             0   \n",
       "4           273          2.0        0              1             2   \n",
       "\n",
       "   review_cool  review_engagement  popularity_score   latitude   longitude  \\\n",
       "0            0                  0          5.135798  40.210196  -75.223639   \n",
       "1            0                  0          3.871201  32.207233 -110.980864   \n",
       "2            1                  2          5.204007  40.079848  -75.025080   \n",
       "3            1                  2          3.496508  29.962102  -90.087958   \n",
       "4            1                  4          5.613128  39.938013  -75.148131   \n",
       "\n",
       "   ...  text_feature_90  text_feature_91  text_feature_92  text_feature_93  \\\n",
       "0  ...         0.163739          0.23642         0.000000         0.000000   \n",
       "1  ...         0.000000          0.00000         0.000000         0.000000   \n",
       "2  ...         0.000000          0.00000         0.000000         0.398945   \n",
       "3  ...         0.136585          0.00000         0.141275         0.163491   \n",
       "4  ...         0.000000          0.00000         0.000000         0.000000   \n",
       "\n",
       "   text_feature_94  text_feature_95  text_feature_96  text_feature_97  \\\n",
       "0              0.0              0.0         0.233233         0.225804   \n",
       "1              0.0              0.0         0.000000         0.000000   \n",
       "2              0.0              0.0         0.000000         0.000000   \n",
       "3              0.0              0.0         0.000000         0.000000   \n",
       "4              0.0              0.0         0.000000         0.000000   \n",
       "\n",
       "   text_feature_98  text_feature_99  \n",
       "0         0.000000         0.000000  \n",
       "1         0.000000         0.000000  \n",
       "2         0.000000         0.000000  \n",
       "3         0.000000         0.358466  \n",
       "4         0.338898         0.000000  \n",
       "\n",
       "[5 rows x 111 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "review_count       0\n",
      "price_range        0\n",
      "is_open            0\n",
      "review_useful      0\n",
      "review_funny       0\n",
      "                  ..\n",
      "text_feature_95    0\n",
      "text_feature_96    0\n",
      "text_feature_97    0\n",
      "text_feature_98    0\n",
      "text_feature_99    0\n",
      "Length: 111, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = data[0]  # Extract DataFrame\n",
    "\n",
    "# Check basic info\n",
    "print(df.info())\n",
    "\n",
    "# Show first few rows\n",
    "display(df.head())\n",
    "\n",
    "# Check for missing values\n",
    "print(df.isnull().sum())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "benmain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
